{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 셀레니움_기본설정\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# 크롬 드라이버 자동 업데이트\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# 브라우저 꺼짐 방지\n",
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "# 불필요한 에러 메시지 없애기\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "\n",
    "service = Service(executable_path=ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# 웹페이지 주소 이동\n",
    "driver.get(\"http://www.naver.com\")\n",
    "\n",
    "# 3. 네이버 로그인 자동화\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# 크롬 드라이버 자동 업데이트\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "import time\n",
    "import pyautogui\n",
    "import pyperclip\n",
    "\n",
    "chrome_options = Options()\n",
    "chrome_options.add_experimental_option(\"detach\", True)\n",
    "\n",
    "# 불필요한 에러 메시지 없애기\n",
    "chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-logging\"])\n",
    "\n",
    "service = Service(executable_path=ChromeDriverManager().install())\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "# 웹페이지 주소 이동\n",
    "driver.implicitly_wait(5)  # 웹페이지가 로딩 될때까지 5초는 기다림\n",
    "driver.maximize_window()  # 화면 최대화\n",
    "driver.get(\"https://nid.naver.com/nidlogin.login?mode=form&url=https://www.naver.com/\")\n",
    "\n",
    "# 아이디 입력창\n",
    "id = driver.find_element(By.CSS_SELECTOR, \"#id\")\n",
    "id.click()\n",
    "# id.send_keys(\"tldus0_0\")\n",
    "pyperclip.copy(\"tldus0_0\")\n",
    "pyautogui.hotkey(\"ctrl\", \"v\")\n",
    "time.sleep(2)\n",
    "\n",
    "# 비밀번호 입력창\n",
    "pw = driver.find_element(By.CSS_SELECTOR, \"#pw\")\n",
    "pw.click()\n",
    "# pw.send_keys(\"   \")\n",
    "pyperclip.copy(\"   \")\n",
    "pyautogui.hotkey(\"ctrl\", \"v\")\n",
    "time.sleep(2)\n",
    "\n",
    "# 로그인 버튼\n",
    "login_btn = driver.find_element(By.CSS_SELECTOR, \"#log\\.login\")\n",
    "login_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get(\"https://finance.naver.com/\")\n",
    "\n",
    "html = response.text\n",
    "\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "# id 값이 NM_set_home_btn인 놈 한개를 찾아냄\n",
    "Word = soup.select_one(\"#menu > ul > li.m1.first.on > a > span.tx\")\n",
    "\n",
    "print(Word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 뉴스제목\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get(\n",
    "    \"https://search.naver.com/search.naver?where=news&sm=tab_jum&query=%EC%82%BC%EC%84%B1%EC%A0%84%EC%9E%90\"\n",
    ")\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "links = soup.select(\".news_tit\")  # 결과는 리스트\n",
    "\n",
    "for link in links:\n",
    "    title = link.text  # 태그 안에 텍스트요소를 가져온다\n",
    "    url = link.attrs[\"href\"]  # href의 속성값을 가져온다\n",
    "    print(title, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색어 변경하기 01\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "keyword = input(\"검색어를 입력하세요>>>\")\n",
    "response = requests.get(\n",
    "    \"https://search.naver.com/search.naver?where=news&sm=tab_jum&query=\" + keyword\n",
    ")\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "links = soup.select(\".news_tit\")  # 결과는 리스트\n",
    "\n",
    "for link in links:\n",
    "    title = link.text  # 태그 안에 텍스트요소를 가져온다\n",
    "    url = link.attrs[\"href\"]  # href의 속성값을 가져온다\n",
    "    print(title, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색어 변경하기 02\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pyautogui\n",
    "\n",
    "keyword = pyautogui.prompt(\"검색어를 입력하세요.\")\n",
    "response = requests.get(\n",
    "    f\"https://search.naver.com/search.naver?where=news&sm=tab_jum&query={keyword}\"\n",
    ")\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "links = soup.select(\".news_tit\")  # 결과는 리스트\n",
    "\n",
    "for link in links:\n",
    "    title = link.text  # 태그 안에 텍스트요소를 가져온다\n",
    "    url = link.attrs[\"href\"]  # href의 속성값을 가져온다\n",
    "    print(title, url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 여러페이지 가저오기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pyautogui\n",
    "\n",
    "keyword = pyautogui.prompt(\"검색어를 입력하세요.\")\n",
    "lastpage = pyautogui.prompt(\"마지막 페이지번호를 입력해주세요\")\n",
    "pageNum = 1\n",
    "for i in range(1, int(lastpage) * 10, 10):\n",
    "    print(f\"\\n{pageNum}페이지입니다.\\n\")\n",
    "    response = requests.get(\n",
    "        f\"https://search.naver.com/search.naver?where=news&sm=tab_jum&query={keyword}&start={i}\"\n",
    "    )\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    links = soup.select(\".news_tit\")  # 결과는 리스트\n",
    "\n",
    "    for link in links:\n",
    "        title = link.text  # 태그 안에 텍스트요소를 가져온다\n",
    "        url = link.attrs[\"href\"]  # href의 속성값을 가져온다\n",
    "        print(title, url)\n",
    "    pageNum = pageNum + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주식 크롤링\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import openpyxl\n",
    "\n",
    "fpath = r\"file_path\"\n",
    "\n",
    "wb = openpyxl.Workbook()\n",
    "codes = [\"005930\", \"000660\", \"035720\"]\n",
    "ws = wb.create_sheet(\"stock\")\n",
    "\n",
    "i = 2\n",
    "for code in codes:\n",
    "    url = f\"https://finance.naver.com/item/sise.naver?code={code}\"\n",
    "    response = requests.get(url)\n",
    "    html = response.text\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    name = soup.select_one(\"#middle > div.h_company > div.wrap_company > h2 > a\").text\n",
    "    ws[f\"A{i}\"] = name\n",
    "    price = soup.select_one(\"#_nowVal\").text\n",
    "    price = price.replace(\",\", \"\")\n",
    "    ws[f\"B{i}\"] = price\n",
    "    i += 1\n",
    "\n",
    "wb.save(fpath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
